\documentclass[doc,a4paper,12pt]{apa6}
\usepackage[a4paper]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage[doublespacing]{setspace}
\usepackage{paralist}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{epstopdf}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{csquotes}
\usepackage[hidelinks]{hyperref}
\usepackage{pdfpages}
\usepackage[backend=biber,style=apa]{biblatex}
\usepackage[titles]{tocloft}
\usepackage{subcaption}

\hypersetup{hidelinks}
\usepackage{letltxmacro}
\makeatletter
\AtBeginDocument{%
  \@ifdefinable{\myorg@nameref}{%
    \LetLtxMacro\myorg@nameref\nameref
    \DeclareRobustCommand*{\nameref}[1]{%
      \glqq{\myorg@nameref{#1}}\grqq%
    }%
  }%
}
\makeatother

\DeclareLanguageMapping{ngerman}{ngerman-apa}
\DefineBibliographyStrings{ngerman}{andothers={et\ al\adddot}}

% spacing list
\setlength{\pltopsep}{1em}
% matrix/vector bold
\newcommand{\mx}[1]{\mathbf{#1}}
\renewcommand{\arraystretch}{1.2}

\bibliography{references}
 
\title{Intrinsische Rauschunterdückung bei LCMV Beamformer und Minimum Norm Estimate bei Magnetenzephalographie}
\shorttitle{Rauschunterdrückung bei LCMV Beamformer}
\author{Carlo Michaelis}
\date{12. August 2015}
%\affiliation{geb. am 29.09.1989 in Dieburg\\ Institut für Psychologie, Universität Leipzig\\ \ }

\renewcommand{\cftfigpresnum}{Abb. }
\settowidth{\cftfignumwidth}{Abb. 10\quad}

\geometry{a4paper, bottom=1.5in}
\setlength{\skip\footins}{1.5em}
\setlength{\footnotesep}{1.5em}
\setlength{\textfloatsep}{2em}
\raggedbottom

\begin{document}

%\maketitle

\thispagestyle{empty}

\begin{spacing}{1.1}
\begin{center}

\Large Universität Leipzig

\setlength{\parskip}{0.8em}
\normalsize Fakultät für Physik und Geowissenschaften

\setlength{\parskip}{6em}
\LARGE \textbf{Intrinsische Rauschunterdückung bei LCMV Beamformer und Minimum Norm Estimate bei Magnetenzephalographie}

\setlength{\parskip}{1.8em}
\normalsize Abschlussarbeit zur Erlangung des akademischen Grades\\ Bachelor of Science (B.Sc.)

\setlength{\parskip}{1.2em}
\normalsize vorgelegt von

\setlength{\parskip}{1.8em}
\Large \textbf{Carlo Michaelis}

\setlength{\parskip}{0.5em}
\normalsize geb. am 29.09.1989 in Dieburg

\setlength{\parskip}{3em}

Erstgutachterin: Herr Dr. Burkhard Maess

\setlength{\parskip}{0.3em}
Zweitgutachter: Herr Prof. Dr. Jürgen Haase

\vfill

Dieses Dokument ist unter folgender Lizenz veröffentlicht:\\ \href{http://creativecommons.org/licenses/by-sa/4.0/}{Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)}

\end{center}
\end{spacing}
\newpage

\section*{Selbstständigkeitserklärung}

Ich versichere hiermit, dass ich die vorliegende Arbeit selbständig verfasst und keine
anderen als die im Literaturverzeichnis angegebenen Quellen benutzt habe.\\
Alle Stellen, die wörtlich oder sinngemäß aus veröffentlichten oder noch nicht veröffentlichten
Quellen entnommen sind, sind als solche kenntlich gemacht.\\
Die Zeichnungen oder Abbildungen in dieser Arbeit sind von mir selbst erstellt worden oder
mit einem entsprechenden Quellennachweis versehen.\\
Diese Arbeit ist in gleicher oder ähnlicher Form noch bei keiner anderen Prüfungsbehörde
eingereicht worden.

\vspace{3em}
\noindent Leipzig, den XX.XX.2015\\ Carlo Michaelis

\newpage

\section*{Zusammenfassung}

...

\newpage

\setcounter{tocdepth}{2}
\tableofcontents
\newpage

\listoffigures
\newpage

\section{Einleitung}

Auf dem Weg des Verstehens des eigenen menschlichen Geistes, kam es in den letzten Jahren - ca. seit Mitte der 1990er Jahre - zu einer beschleunigten Entwicklung von Verfahren und Methoden zur Messung der Gehirnaktivität, was seit dem zu einem deutlich besseren Verständnis der zerebralen Prozesse beigetragen hat. Vor allem der rasant zunehmenden und günstiger werdenden Computertechnologie ist es zu verdanken, dass heute Berechnungen möglich sind, die selbst vor 10 Jahren noch nahezu undenkbar waren. Es wird jedoch immer deutlicher, dass diese Entwicklung erst am Anfang steht. Neben der direkten Messung zerebraler Aktivitäten - wie es in dieser Arbeit der Fall ist - wird es zunehmend auch zu Simulation von Lernprozessen kommen, was durch den aktuellen Aufschwung künstlicher neuronaler Netzwerke, insbesondere durch Deep Learning derzeit deutlich wird \parencite[z.B.][]{ciresan2012multi}.

Die Quellen (Orte) und Aktivitäten (Potentiale ??) sind die zentralen Größen bei der Untersuchung des Gehirns. Unterschiedliche Verfahren eigenen sich entsprechend ihrer Eigenschaften eher um Quellen in hoher räumlicher Auflösung oder Aktivitäten in hoher zeitlicher Auflösung zu messen. Dabei werden im Folgenden nur nicht-invasiven Verfahren betrachtet. Eine Bildgebung, also die Bestimmung der physikalischen Quellen im Gehirn mit möglichst hoher räumlicher Auflösung, wird klassisch mit tomographischen Verfahren ermöglicht, z.B. Magnet-Resonanz-Tomographie (MRT) und Computertomographie (CT). Enzephalografische Verfahren sind auf eine hohe zeitliche Auflösung der zerebralen Aktivität spezialisiert. Zu diesen gehören Elektroenzephalographie (EEG) und Magnetenzephalographie (MEG).

Mit zunehmender Rechenkapazität und entsprechenden Modellen lassen sich inzwischen auch mit enzephalografischen Verfahren (z.B. EEG, MEG) die Quellen der Aktivität bestimmten. Die Messung erfolgt dabei nur an der Oberfläche des Kopfes, eine Lokalisation erfolgt somit indirekt. Diese Verfahren haben den entscheidenden Vorteil, dass ihre zeitliche Auflösung meist enorm hoch ist, sie können Veränderungen im Gehirn noch im Millisekundenbereich erfassen. Zum Vergleich: Bildgebende funktionelle Verfahren, welche zusätzlich zur Bildgebung auch die Aktivität erfassen können - wie die funktionelle Magnet-Resonanz-Tomographie (fMRT) - liegen hier meist nur im Bereich von Sekunden. Auch wenn die enzephalografischen Verfahren in der zeitlichen Auflösung sehr schnell sind, ihr Nachteil bleibt nach wie vor noch eher unpräzise Lokalisationsfähigkeit. Bei MEG-Messungen kommt erschwerend die hohe Verrauschung der Daten hinzu. Während die Messgrößen im Bereich von Femto-Tesla liegen, ist selbst der Herzschlag am Gehirn noch im Bereich von Picotesla messbar. Netzstrom und die Vielfachen dessen Eigenschwingung ($50\,Hz$, $100\,Hz$, $150\,Hz$, etc.), sowie die Schwingung des Bahnnetzes ($16,67\,Hz$) am konkreten Standort des Max-Planck-Insituts für kognitive Neurowissenschaften in Leipzig sind trotz starker Abschirmung deutlich messbare Größen in jeder MEG-Messung (siehe auch Abschnitt \nameref{sec:rauschen} auf Seite \pageref{sec:rauschen}). Die Frequenzen der Artefarkte in den Rohdaten lassen sich mit Hilfe einer Fourier-Analyse berechnen, siehe Abbildung ???.

Verschiedene Faktoren beeinflussen folglich die Messung, die niemals unter idealen Bedingungen statt findet. Es liegen unterschiedliche Möglichkeiten der Vermeidung und Unterdrückung vor. Während der Hersteller des verwendeten Gerätes \emph{Vectorview by Elekta-Neuromag Oy, Helsinki} die Software \emph{Maxfilter} mit liefert, mit der eine Trennung zwischen äußeren und inneren Quellen möglich ist (siehe Abschnitt \nameref{sec:maxfilter} auf Seite \pageref{sec:maxfilter}), soll es Ziel dieser Bachelorarbeit sein die Robustheit verschiedener Verfahren gegenüber den angesprochenen Rauschgrößen zu erproben. Dabei werden die Verfahren mit und ohne voriger Verwendung von Maxfiter gegenübergestellt.

Die Hypothese soll lauten, dass Beamformer relativ stabil gegenüber Rauschen sein müsste und eine Anwendung softwareseitiger Filterverfahren nicht nötig ist, um eine gute Quelllokalisation zu erreichen, während Minimum Norm Estimate ohne vorherige Anwendung von Filterverfahren eher zu unpräziseren Ergebnissen führen sollte. Die Hypothese wird im entsprechenden Abschnitt auf Seite \pageref{sec:hypo} formuliert und begründet.

Im Folgenden werden zunächst die Grundlagen zur Biologie, zum Messverfahren und Rauschen erläutert. Anschließend soll noch innerhalb der Einleitung auf die Quelllokalisation und die dafür benötigten Modelle eingegangen werden. Im Abschnitt \nameref{sec:methodik} ab Seite \pageref{sec:methodik} wird dann beschrieben wie die formulierte These geprüft wurde, deren Ergebnisse dann im Abschnitt \nameref{sec:ergebnisse} und \nameref{sec:diskussion} ab den Seiten \pageref{sec:ergebnisse} und \pageref{sec:diskussion} vorgestellt und diskutiert werden.

% #################################
% ##### GRUNDLAGEN BIOLOGISCH #####
% #################################

\subsection{Biologische Grundlagen}

\subsubsection{Kopf- und Gehirnstruktur}
\label{sec:head-struct}

Der Kopf als Träger des Gehirns besteht aus mehreren Komponenten, deren Begriffe im Folgenden regelmäßig verwenden werden. Die Kopfoberfläche (head shape) bzw. Kopfhaut (scalp) ist der äußerste Bereich. An diesem liegen bei EEG- und MEG-Messungen die Sensoren zur Messung an (bzw. kurz darüber). Unterhalb der Kopfoberfläche befindet sich der Schädelknochen, welcher das darin liegende Gehirn schützt. Das Gehirn wiederum ist von einer Bindegewebsschichten umgeben, der Hirnhaut. Die Gehirnmasse selbst, lässt sich grob in zwei Bereiche einteilen, die graue Substanz und die weiße Substanz. Während die graue Substanz eine hohe Dichte an Zellkörpern und eher weniger myelinisierte Axone enthält, enthält die weiße Substanz entsprechend viele lange und myelinisierte Axone und eher weniger Zellkörper. Im Gehirn liegt die graue Substanz eher in äußeren Bereichen und umhüllt die weiße Substanz. Die beiden groben Typen der Gehirnmasse weisen unterschiedliche messtechnische Eigenschaften auf, so ist die Leitfähigkeit der grauen Substanz isotrop, während die der weißen Substanz anisotrop ist \parencite{logothetis2007vivo}.

\subsubsection{Elektrische und magnetische Eigenschaften der Nervenzellen}

Alle Nervenzellen des Körpers kommunizieren durch kleine elektrische Ströme. Dabei können zwei unterschiedliche Arten der elektrischen Aktivität unterschieden werden \parencite{da1998biophysical}. Die \emph{postsynaptischen Potentiale} und die u.U. daraus resultierenden \emph{Aktionspotentiale}. Im Gleichgewicht besitzen Nervenzellen ein \emph{Ruhepotential} im Bereich von ca. $-70\,mV$. Graduelle lokale Änderungen des Membranpotentials werden als \emph{exzitatorisches postsynaptisches Potential} (EPSP) bezeichnet, wenn sie zur Auslösung eines Aktionspotentials beitragen. \emph{Inhibitorische postsynaptisches Potential} (IPSP) bezeichnen im Gegensatz graduelle Potentialveränderungen, die der Auslösung eines Aktionspotentials entgegenwirken. Wird ein bestimmter Potential-Schwellwert, der bei ca. $-55\,mV$ liegt, überschritten, so kommt es zu einer beschleunigten Ausschüttung von Ionen, welches zu einer starken Potential-Verschiebung auf bis zu $+20\,mV$ bis $+30\,mV$ führt. Das Aktionspotential dauert jedoch nur ca. $1\,ms$ bis $2\,ms$ und wird während seiner Ausbreitung über mehrere Nervenzellen schnell wieder abgedämpft. Da zusätzlich die Wahrscheinlichkeit für eine präzise synchrone Ausbreitung sehr gering ist, ist die Messung der elektrischen und magnetischen Felder eines Aktionspotential sehr unwahrscheinlich. Was hingegen gut erfasst werden kann sind die postsynaptischen Potentiale. Die Potentiale breiten sich - verglichen mit dem Aktionspotential - langsamer und gleichmäßiger über größere Nervenzellen-Strukturen aus. Die von ihnen verursachten elektrischen und magnetischen Felder können an der Oberfläche, d.h. außerhalb der Kopfhaut, gemessen werden.

\subsubsection{ERP und ERF}
\label{sec:erf}

Das \emph{event-related potential} (Ereigniskorreliertes Potential, ERP) bezeichnet ein elektrisches Potential, welches im Gehirn auftritt und mit einem EEG (Elektroenzephalogramm) detektiert werden kann. Es tritt leicht verzögert mit einem bestimmten Ereignis in der Umwelt auf. Da im MEG (Magnetenzephalogramm) im Gegensatz zum EEG keine Potentiale, sondern nur Felder und deren Verteilungen und Intensität gemessen werden kann, wird dort der Begriff des \emph{event-related field} (Ereigniskorreliertes Feld, ERF) eingeführt.

Ein klassisches Beispiel eines ERP bzw. ERF ist die MMN, die so genannte \emph{missmatch negativity}. Das Ereignis ist in diesem Fall die Änderung eines zuvor geregelten Stimulus. Werden z.B. hinreichend viele Töne gleicher Höhe, Länge und Lautstärke am gleichen Ohr abgespielt und folgt dann eine Änderung des Stimulus, z.B. andere Höhe, Länge, Lautstärke oder eine Präsentation am anderen Ohr (Oddball-Paradigma), so folgt auf dieses Ereignis eine Änderung des elektrischen Potentials im Gehirn bzw. eine Änderung des magnetischen Feldes im Gehirn im Abstand von ca. $150-250\,ms$ zum Stimulus. Das Ereignis (``anderer Ton'') ist korreliert mit dem Auftreten eines Potentials (ERP) bzw. eines Feldes (ERF) im Gehirn.

\subsubsection{Auditorischer Kortex}
\label{sec:audicort}

\begin{figure}[t]
%  \centering
%  \captionsetup{justification=centering}
  %
  \begin{subfigure}[c]{0.47\textwidth}
    \fbox{\includegraphics[width=\textwidth]{einleitung/stg.png}}
    \subcaption{Gyrus temporalis superior (STG), enthält den auditorischen Kortex.\\ Verwendet von \glqq Auditory cortex\grqq .\\ (18. März 2015). In Wikipedia, The Free Encyclopedia. Abgerufen 19:47, 04. August 2015, von \url{https://en.wikipedia.org/w/index.php?title=Auditory_cortex&oldid=653871107}}
    \label{img:gyrustemp}
  \end{subfigure}\hspace*{0.04\textwidth}
  %
  \begin{subfigure}[c]{0.47\textwidth}
    \fbox{\includegraphics[width=\textwidth]{einleitung/brodmann-41-42.png}}
    \subcaption{Auditorischer Kortex in den Brodmann Arealen 41 und 42.\\ Verwendet von \glqq Superior temporal gyrus\grqq.\\ (20. Juli 2015). In Wikipedia, The Free Encyclopedia. Abgerufen 19:57, 04. August 2015, von \url{https://en.wikipedia.org/w/index.php?title=Superior_temporal_gyrus&oldid=672262435}}
    \label{img:audicort}
  \end{subfigure}
  %
  \vspace*{3mm}
  \caption{Gyrus temporalis superior (STG) und auditorischer Kortex}
  \label{img:audi}
\end{figure}

Der auditorische Kortex ist ein bestimmter Bereich des Gehirns. Er befindet sich an den Brodmann Arealen 41 und 42, dargestellt in Abbildung \ref{img:audicort}. Der auditorische Kortex ist Teil des Gyrus temporalis superior (STG, sieh Abbildung \ref{img:gyrustemp}), welcher bei jeglicher auditiver Stimulation aktiviert wird \parencite{binder1994functional}. Im auditorischen Kortex erfolgt dann das Bewusstwerden akustischer Signale \parencite{jaaskelainen2004human}.

In den vorliegenden Daten handelt es sich um ein auditives Experiment, weshalb die ERF (v.a. die MMN) im auditorischen Kortex erwartet werden.

% ###########################
% ##### GRUNDLAGEN MEG  #####
% ###########################

\subsection{Grundlagen der Magnetenzephalographie}

Das MEG (Magnetenzephalographie) misst die magnetischen Aktivität des Gehirns. Es ist das zweitjüngste Verfahren zur Messung der Gehirnströme. Nachdem in den 1920er Jahren das EEG durch Hans Berger entwickelt und 1929 erstmals publiziert wurde \parencite{berger1929elektrenkephalogramm}, folgte das MEG erst 1968 \parencite{cohen1968magnetoencephalography}, war damit aber noch vor anderen Verfahren zur Vermessung des Gehirns, wie dem CT (Computertomographie) oder dem MRT (Magnet-Resonanz Tomographie). Trotzdem ist das MEG auf Grund seiner hohen Empfindlichkeit, seiner damit verbundenen hohen Rauschanfälligkeit und ebenso auf Grund seines noch unausgeschöpften Lokalisations-Potentials auch heute noch ein Verfahren, welches sich in einem kontinuierlichen Optimierungsprozess befindet.

Da die Kosten eines MEG deutlich über denen eines EEG liegen, stellt sich die berechtigte Frage warum überhaupt die magnetische Komponente der Nervenzellen-Aktivität gemessen wird. Zusätzlich lassen sich mit MEG nur die tangentialen Komponenten der Aktivität messen, während EEG sowohl tangentiale, als auch radiale Aktivität erfassen kann. Die Vorteile des MEG liegen jedoch in einer geringeren Störung der magnetischen Signale durch den Schädel und die Kopfhaut, und einer damit verbundenen höheren räumliche Auflösung. Während das EEG also mehr Aktivität erfassen kann, ist das MEG präziser in der Erfassung und ermöglicht eine genauere Lokalisation. Zusätzlich ist die zeitliche Auflösung unterhalb einer Millisekunde $< 10^{-3}\,s$, die hohe Anzahl der Kanäle und die genaue Kenntnis über die Position der Kanäle (auf Grund des starren MEG-Helms) wichtige Vorteile des MEG zur Lokalisation der Quellen  \parencite{malmivuo2012comparison}.

\subsubsection{SQUIDs}
\label{sec:squids}

Technische Grundlage der Magnetenzephalographie bilden SQUIDs (Superconducting Quantum Interference Device, dt.: Supraleitende Quanteninterferenzeinheit), welche 1964 in den Ford Research Labs entwickelt wurden \parencite{jaklevic1964quantum}. Sie basieren auf dem Josephson Effekt, der bereits 1962 von Brian D. Josephson vorhergesagt wurde \parencite{josephson1962possible}. Josephson sagte voraus, dass zwei Supraleiter, welche durch eine wenige Nanometer dicke nicht-supraleitende Schicht getrennt werden (Josephson-Kontakt) und mit einem geringen elektrischen Strom durchflossen werden, von Cooper-Paaren derart durchtunnelt werden können, dass sich der Josphson-Kontakt wie ein unterbrechungsfreier Supraleiter verhält. Die Cooper-Paare tunneln in dem Fall widerstandsfrei.
Auf Grund der Cooper-Paare sind die Wellenfunktion zweier Elektronen gekoppelt (abhängig von der dicke der Schicht). Mit den Wellenfunktionen $\Psi_1$, $\Psi_2$ und den Hamilton-Operatoren $H_1$, $H_2$, sowie dem Kopplungskoeffizienten $T$ gilt:

\begin{subequations}
\label{eq:cooper}
  \begin{equation} i\hbar \frac{\partial \Psi_1}{\partial t} = H \Psi_1 + T \Psi_2 \end{equation}
   \begin{equation} i\hbar \frac{\partial \Psi_2}{\partial t} = H \Psi_2 + T \Psi_1 \end{equation}
\end{subequations}

Die erste Josphson-Gleichung beschreibt die Abhängigkeit des Stroms im Supraleiter $I_S$ vom kritischen Strom $I_0$, wobei $\Delta \phi$ die Phasendifferenz zwischen den zwei Wellengleichungen \ref{eq:cooper} bezeichnet.

\begin{equation}
\label{eq:joseph}
I_S = I_0\,\sin{\Delta \varphi}
\end{equation}

Gleichung \ref{eq:joseph} gilt jedoch nur für Prozesse ohne Magnetfeld. Sobald ein Magnetfeld anliegt, muss die Gleichung korrigiert werden. Es liegt eine Abhängigkeit des Strom im Supraleiter $I_S$ vom anliegenden Magnetfeld $\vec{B}$ bzw. vom zugehörigen magnetischen Vektorpotential $\vec{A}$ vor:

\begin{equation}
\label{eq:josephfeld}
I_S = I_0\,\sin{\left( \Delta \varphi - \frac{2\pi}{\Phi_0} \int_{S1}^{S2} \vec{A}\,d\vec{l} \right)}
\end{equation}

Der zweite Term ergänzt Gleichung \ref{eq:joseph} um ein Wegintegral vom ersten Supraleiter $S1$ über den Josephson-Kontakt zum zweiten Supraleiter $S2$. $\Phi_0$ entspricht dem Flussquant (siehe auch Gleichung \ref{eq:flussquant}).

Ein SQUID basiert auf diesem Prinzip und enthält zwei Josephson-Kontakte, in welchem ein Gleichsstrom fließt (DC SQUID) oder einen Josephson-Kontakt, in welchem ein Wechselstrom fließt (RF SQUID). Die Leiter in einem SQUID sind zu einem Ring zusammengeschlossen. Entscheidend ist, dass sich der Strom innerhalb des SQUID abhängig vom äußeren Magnetfeld verhält, wie in Gleichung \ref{eq:josephfeld} gezeigt. Das anliegende Magnetfeld kann auf einzelne Flussquanten genau angegeben werden. Ein Flussquant entspricht:

\begin{equation}
\label{eq:flussquant}
\Phi_0 = \frac{h}{2e} \approx 2,068\,Tm^2
\end{equation}

Die magnetische Flussdichte der Gehirnaktivität liegt im Bereich von wenigen $10^{-15}\,T$ und kann daher nur mit hochsensiblen Sensoren gemessen werden. Zum Einsatz kommen daher SQUIDs.

\subsubsection{Flux-Transformator}

\begin{figure}[t]
  \centering
  \setlength{\fboxsep}{8mm}
  \fbox{\includegraphics[width=0.6\textwidth]{einleitung/koppelspule.eps}}
  %
  \vspace*{3mm}
  \caption[Prinzip eines Flux-Transformators]{Prinzip eines Flux-Transformators. An der Aufnahmespule wird vom magnetischen Feld ein Strom induziert. Die Koppelspule erzeugt ein äquivalentes magnetisches Feld in unmittelbarer Nähe des SQUID.}
  \label{img:flux-trafo}
\end{figure}

Um die Signale zu erfassen wird ein \emph{Flux-Transformator} eingesetzt, welcher das Signal an einen SQUID weiterleitet. Der Flux-Transormator wird so nah wie möglich an den Kopf der Versuchsperson gebracht (im Bereich von ca. $2\,cm$). Ein vom Gehirn der Versuchsperson erzeugtes magnetisches Feld erzeugt an einer Aufnahmespule einen Strom. Dieser wird über eine Koppelspule wieder in ein äquivalentes Magnetfeld zurückgeführt. Die Koppelspule befindet sich in unmittelbarer Nähe des SQUID, an dem das Signal letztlich messbar wird. Der Sachverhalt ist in Abbildung \ref{img:flux-trafo} dargestellt. Der Flux-Transformator wird in zwei verschiedenen Varianten verwendet, dem Magnetometer und dem Gradiometer.

\subsubsection{Magnetometer und Gradiometer}

Magnetometer besitzen nur einen Ring an der Aufnahmespule des Flux-Transformators, sie messen den absoluten Wert der magnetischen Flussdichte in radiale Richtung $B_z$ in $T$. Neben der hohen Sensitivität gegenüber nahen Quellen, wie magnetische Aktivität im Gehirn, erfassen Magnetometer auch Signale aus weiter Entfernung und damit ungewünschte Aktivität aus der Umgebung \parencite{hansen2010meg}. Beispielsweise erreicht ein fahrendes Auto in $2\,km$ Entfernung eine Signalstärke, die mit dem der Gehirnaktivität äquivalent ist \parencite{weinstock2012squid}.

Gradiometer besitzen zwei Aufnahmespule am Flux-Transformator. Die zwei Ringe eines Gradiometers können axial oder planar angeordnet sein. Die zwei Spule messen einen räumlichen Gradienten. Der Gradient der magnetische Flussdichte $G_x = dB_z/dx$ bzw. $G_y = dB_z/dy$ wird in $T/m$ angegeben. Die Annahme ist, dass weit entfernte Quellen ein relativ homogenes Feld erzeugen. Da die zwei Aufnahmespulen des Gradiometers mit einem entgegengesetzten Strom durchflossen werden und die gemessenen magnetischen Flussdichten voneinander subtrahiert werden, verschwindet der Gradient für weit entfernte Quellen im Idealfall, so dass nur nahe Quellen erfasst werden \parencite{hansen2010meg}.

Im Falle des verwendeten MEG-Systems (\emph{Vectorview by Elekta-Neuromag Oy, Helsinki}) enthält jeder der 102 Sensoren drei Kanäle mit einem Magnetometer und zwei Gradiometern, die je in $x$- und $y$-Richtung ausgerichtet sind.

\subsection{Artefakte und Rauschen}

Wie bereits im Abschnitt \nameref{sec:squids} auf Seite \pageref{sec:squids} deutlich wurde, ist das MEG ein äußerst empfindliches Messinstrument, welche im Bereich einzelner Flussquanten $\Phi_0$ messen kann. Ziel ist es nur die Gehirnsignale zur weiteren Berechnung zu verwenden und alle anderen Störfaktoren auszuschließen. Dafür kann eine Reihe von Maßnahmen getroffen und entsprechende Software eingesetzt werden, die im Folgenden erläutert wird.

\subsubsection{Allgemeine Rauschunterdrückung}
\label{sec:rauschen}

Prinzipiell können unterschiedliche Artefakte und Rauschfaktoren ausgemacht werden. Grob können drei Bereiche klassifiziert werden: (1) Umwelt, (2) Versuchsperson und (3) Messtechnik.

Am besten zu beeinflussen ist der Faktor der Umwelt (1). Innerhalb von Städten ist beispielsweise viel bewegtes Metall (z.B. Autos, Straßenbahnen), welches zu schwachen, aber deutlich messbaren Magnetfeldern führt. Zusätzliche treten viele periodische elektrische und magnetische Felder auf (z.B. Netzkabel, Oberleitungen). All diese Faktoren können durch eine entsprechende Standortwahl deutlich verringert werden. Die verbleibenden Faktoren können durch ein stark geschirmten Messraum weiter verringert werden. Verbleibende Faktoren sind meist trotzdem deutlich in den Messungen sichtbar (z.B. Netzkabel im Gebäude).

Auch die Versuchsperson (2) hat einen großen Einfluss auf die Messung. Bewegung der Augen, Herzschläge und Kopfbewegungen, allgemein jede Kontraktion eines Muskels, führt zu deutlich messbaren mehr oder weniger periodischen Artefakten. Durch ein gutes Versuchsdesign und eine professionelle Einweisung können einige dieser Faktoren verringert werden, letztlich ist die Disziplin der Versuchsperson jedoch der entscheidende Faktor.

Letztlich hat auch die Messtechnik (3) in Form klassischen Rauschens einen entscheidenden Einfluss, maßgeblich durch Sensorrauschen.

\textcite{vigario1998independent} und \textcite{vigario2000independent} fassten mit Hilfe einer ICA (Independent Component Analysis) die wichtigsten Faktoren für Rauschen und Artefakte bei MEG-Messungen zusammen. Es ergaben sich folgende allgemeine Faktoren für Artefakte der Versuchsperson (2):

\begin{compactitem}
\item Gebiss-Muskulatur
\item Horizontale Augenbewegung und Blinzeln
\item Herzmuskel
\item Atmung
\end{compactitem}

\subsubsection{Softwareseitige Rauschunterdrückung}
\label{sec:maxfilter}

Nachdem das Rauschen bereits während der Messung versucht wird so gut wie Möglich zu unterdrücken, kann auch auf Softwareebene nachgearbeitet werden. Eine Möglichkeit bietet die \emph{Signal-space projection} (SSP), für die eine Leerraummessung notwendig ist. Eine andere rechenintensivere Möglichkeit bietet die proprietäre Software Maxfilter von Neuromag (siehe auch Abschnitt \nameref{sec:software} auf Seite \pageref{sec:software}), die \emph{Signal-Space Separation} (SSS) zur Trennung äußerer und innerer Quellen anwendet. Mit \emph{Movement Correction} (MC) können zusätzlich die Bewegungen der Versuchsperson nachträglich korrigiert werden.

Der Signalraum (signal-space) ist ein $n$-dimensionaler Raum, wobei $n$ der Anzahl der Kanäle entspricht. Ein Vektor bzw. ein Punkt im Signalraum entspricht einem vollständigen Signal zu einem Zeitpunkt. Das räumliche Muster des Signals entspricht der Richtung des Vektors, die Intensität des Signals entspricht dem Betrag des Vektors \parencite{hansen2010meg}.

SSP wurde Ende der 90er Jahre von \textcite{uusitalo1997signal} und \textcite{parkkonen1999interference} entwickelt. Die Methode basiert auf dem Vorliegen einer Leerraummessung. In einer kurzen Messung werden die üblichen magnetischen Aktivitäten im Messraum aufgezeichnet, ohne dass eine Versuchsperson anwesend ist. Das Ergebnis entspricht den Umwelt-Artefakten, die als zeitlich konstant angesehen werden und zu jeder späteren Messung vorhanden sind. Wird eine Messung mit Versuchsperson durchgeführt, so bildet die Leerraummessung einen Unterraum des gewöhnlichen Signalraums. Durch eine orthogonale Projektion des Signalraums auf den Unterraum der Leerraumessung, ergibt sich ein weiterer Unterraum, der die Signale ohne die Umwelteinflüsse enthalten sollte. Jegliche äußeren Artefakte werden damit entfernt oder zumindest drastisch reduziert.

SSS wurde wenige Jahr später von \textcite{taulu2004suppression} und \textcite{taulu2005presentation} entwickelt. Dabei wird das gemessene Magnetfeld in einer Reihenentwicklung beschrieben. Jedes harmonische Potential $V(\mx{r})$ kann beschrieben werden mit:

\begin{equation}
V(\mx{r}) = \sum_{l=1}^\infty \sum_{m=-l}^l \alpha_{lm} \frac{Y_{lm}(\Theta, \varphi)}{r^{l+1}} + \sum_{l=1}^\infty \sum_{m=-l}^l \beta_{lm} r^l Y_{lm}(\Theta, \varphi) 
\label{eq:sss-pot}
\end{equation}

Die Entwicklung in der ersten Summe ist im Ursprung singulär, in der zweiten Summe divergiert sie für unendliches $l$. $Y_{lm}$ ist die normalisierte harmonische Funktion mit den sphärischen Koordinaten $\Theta, \varphi$ und $r$:

\begin{equation}
Y_{lm}(\Theta, \varphi) = \sqrt{\frac{2l+1}{4\pi} \frac{(l-m)!}{(l+m)!}}\, P_{lm}(\cos{\Theta})\,e^{im\varphi}
\end{equation}

Wobei $P_{lm}(\cos{\Theta})$ Legendre-Polynome sind. Das magnetische Potential kann analog entwickelt werden:

\begin{equation}
\Phi = \sum_{l=1}^\infty \sum_{m=-l}^l \alpha_{lm} \mx{a}_{lm} + \sum_{l=1}^\infty \sum_{m=-l}^l \beta_{lm} \mx{b}_{lm}
\label{eq:sss-magpot}
\end{equation}

Die Vektoren $\mx{a}_{lm}$ und $\mx{b}_{lm}$ entsprechen den Termen $Y_{lm}(\Theta, \varphi)/r^{l+1}$ und $r^l Y_{lm}(\Theta, \varphi)$ aus Gleichung \ref{eq:sss-pot}. $\Phi$~kann als Signalvektor interpretiert werden. Bezeichne $n$ weiterhin die Anzahl der Kanäle, dann bilden $n$ linear unabhängige Signalvektoren $\Phi$ den Signalraum. Die SSS-Methode basiert auf diesem Koordinatensystem. Es gilt:

\begin{equation}
\Phi = \mx{S}\,\mx{x} = \left( \mx{S}_{\text{innen}}, \mx{S}_{\text{außen}} \right) \left( \mx{x}_{\text{innen}} \atop \mx{x}_{\text{außen}} \right)
\end{equation}

$\mx{S}_{\text{innen}}$ und $\mx{S}_{\text{außen}}$ werden mit den Basen $\mx{a}_{lm}$ und $\mx{b}_{lm}$ beschrieben, während $\mx{x}_{\text{innen}}$ und $\mx{x}_{\text{außen}}$ von $\alpha_{lm}$ und $\beta_{lm}$ beschrieben werden. Mit Hilfe des aufgestellten Koordinatensystems kann eine räumliche Filterung vorgenommen werden, die in zwei Aspekten von Bedeutung ist:

\begin{compactitem}
\item Vollständig unkorrelierte Signale, wie Artefakte an einzelnen Kanälen oder zufälliges Rauschen der Gerätekomponenten werden sowohl von Termen mit niedrigen, wie auch von Termen mit hohen Indizes beschrieben. Signale von realen Quellen sind in Termen mit hohen Indizes nicht mehr vertreten. Wird die Reihenentwicklung abgebrochen, sobald der Beitrag der realen Quellen nicht mehr relevant ist, kann ein Großteil des Rauschens und der Artefakte, welches auf messtechnischer Ebene entsteht, herausgefiltert werden.
\item Man kann zeigen, dass externe Quellen außerhalb des MEG-Helms mit den Termen in der zweiten Summe von Gleichung \ref{eq:sss-magpot} zusammenhängen. Umgekehrt sind Signale, welche vom Inneren des MEG-Helmes (respektive vom Gehirn) stammen mit den Termen der ersten Summe verknüpft. Intuitiv wird dies in Gleichung \ref{eq:sss-pot} deutlich. Der erste Term enthält - wie bereits angesprochen - eine Singularität im Ursprung, die zweite Summe divergiert für unendlich große $l$. Durch einfaches Weglassen der zweiten Summe werden die Einflüsse der externen Quellen deutlich verringert.
\end{compactitem}

Die SSS-Methode ist zwar deutlich rechenaufwändiger als SSP, führt jedoch im Gegenzug zu deutlich rauschfreieren Ergebnissen. Zusätzlich ist keine Leerraummessung notwendig. Die Methode kann durch die angesprochene Movement Correction (MC) erweitert werden. Im normalen SSS-Verfahren wird angenommen, dass die Versuchsperson während eines Durchgangs bzw. Blocks unbewegt sitzen bleibt. Die Kopfpositionen werden nur zwischen den Blöcken auf die Position zu Beginn der gesamten Messung korrigiert. Bei der zusätzlichen MC-Berechnung wird die Kopfposition für jeden Zeitpunkt korrigiert. Zur Erfassung der Kopfposition sind Spulen am Kopf angebracht, welche zu jedem Zeitpunkt die Position der Versuchsperson erfassen. Eine zusätzliche nachträgliche Korrektur der Kopfposition ist vor allem dann sinnvoll, wenn sich die Versuchsperson sehr viel bewegt hat. Die Notwendigkeit dieses Rechenschritts kann mit Bewegungsprofilen abgeschätzt werden.

% ####################################
% ##### GRUNDLAGEN LOKALISATION  #####
% ####################################

\newpage
\section{Hintergrund zur Quelllokalisation}

Die Messung der magnetischen Signale erfolgt ausschließlich über die außerhalb des Kopfes befindlichen Sensoren. Die entscheidende Frage ist also: Wie ist es möglich anhand der magnetischen Signale außerhalb des Gehirns auf die physiologischen Quellen innerhalb des Gehirns zu schließen? Um diese Frage zu beantworten wird zunächst etwas Theorie eingeführt und anschließend die Vorwärts-Lösung, sowie verschiedene Methoden der inversen Lösung erläutert.

% ###########################
% ##### VORWÄRTSMODELL  #####
% ###########################

\subsection{Grundlagen und Vorwärtsmodell}

\subsubsection{Superposition}

Jede Quelle im Gehirn wirkt auf alle Sensoren an der Kopfoberfläche, jeder Sensor empfängt also Signale jeder einzelnen Aktivität im Gehirn. Es liegt eine Superposition der Quellaktivität vor (siehe Abbildung ???). Ähnlich einer Unterhaltung mit 10 sprechenden Personen und 5 aufnehmenden Mikrofonen. Jedes Mikrofon empfängt aus einer anderen Perspektive alle 10 Gespräche. Wünschenswert wäre es nun ein einzelnes Gespräch zu isolieren \emph{und} zu lokalisieren. Übertragen auf das Gehirn soll versucht werden die Quellen der Aktivitäten zu identifizieren und deren spezifische Aktivitäten über die Zeit zu erhalten. Die Quellen werden durch Dipole beschrieben und diskretisiert. Entsprechend soll für jeden angenommenen Dipol (an einem bestimmten Ort im Gehirn) ein Aktivitätsverlauf über die Zeit berechnet werden.

\subsubsection{Segmentierung und Volumenleiter}

Die Quellbestimmung ist nur an bestimmten Stellen innerhalb des Kopfes wirklich sinnvoll, außerhalb des Gehirns ist kein magnetischer Dipol zu erwarten. Außerdem ist es wünschenswert die Aktivität im Gehirn nicht auf eine standardisierte mathematische Form (z.B. auf eine Kugel) zu berechnen, sondern ein echtes Gehirn zu verwenden, im Idealfall das tatsächliche Gehirn der entsprechenden Versuchsperson. Dafür muss zunächst ein bildgebendes Verfahren eingesetzt werden. Üblicherweise eignet sich dafür ein MRT-Scan des Kopfes.

Das Bild des Kopfes enthält zunächst noch keine Informationen über physiologische Bestandteile. Mit dem Softwarepaket Freesurfer kann das Bild des Kopfes in seine Segmente zerlegt werden (siehe auch \nameref{sec:head-struct} auf Seite \pageref{sec:head-struct}). Es wird unterschieden zwischen der Kopfoberfläche bzw. Kopfhaut, dem Schädel und dem Gehirn. Innerhalb des Gehirns werden graue und weiße Substanz getrennt.

\begin{figure}[t]
  \centering
%  \captionsetup{justification=centering}
  %
  \fbox{\includegraphics[width=0.5\textwidth]{einleitung/bem.png}}
  %
  \vspace*{3mm}
  \caption[Volumenleiter, berechnet mittels Boundary Element Model (BEM)]{Volumenleiter, berechnet mittels Boundary Element Model (BEM). Darstellung der drei segmentierten Bereiche: Gehirn (grün), Schädel (weiß), Kophaut (grau).\\ Verwendet von \glqq Creating a volume conduction model of the head for source-reconstruction of EEG data\grqq . (01. April 2015). In FieldTrip wiki. Abgerufen 15:02, 10. August 2015, von \url{http://www.fieldtriptoolbox.org/tutorial/headmodel_eeg}}
  \label{img:bem}
\end{figure}

Anschließend wird ein Kopfmodell (head model) berechnet, welches die verschiedenen Gewebetypen beinhaltet. Dafür können numerische Verfahren wie z.B. das \emph{Boundary Element Model} (BEM) verwendet werden. Das BEM-Verfahren modelliert die Ränder der segmentierten Volumina mit Dreiecksflächen. Dabei wird angenommen, dass die Leitfähigkeit innerhalb der Volumen isotrop ist. Dies stellt eine Idealisierung da. Im Abschnitt \nameref{sec:head-struct} auf Seite \pageref{sec:head-struct} wurde bereits deutlich, dass eine vollständige homogene Leitfähigkeit nicht der Realität entspricht bzw. nur für die graue Substanz gültig ist. Da die graue Substanz jedoch außen liegt und meist auch nur die Aktivitäten im Außenbereich berechnet werden, ist die Näherung meist gerechtfertigt.

Die Diskretisierung der Oberfläche im BEM-Modell wirkt sich auf die Quellrekonstruktion aus. Wird die Dichte der Netzpunkt zu gering gewählt kommt es zu Fehlern in der numerischen Berechnung, die Quellen werden fehlerhaft geschätzt. Die Seitenlängen der Dreiecke sollten unterhalb von $10\,mm$ liegen. Zusätzlich sollte das Verhältnis von Dipoltiefe zur Seitenlänge der Dreiecke nicht kleiner als $0,5$ sein \parencite{haueisen1997effect}. Die Anzahl der Netzpunkt muss entsprechend hoch genug gewählt werden.

Im Gegensatz zum BEM-Modell wird im FEM-Modell (\emph{Finite Element Model}) angenommen, dass die Leitfähigkeit anisotrop ist. Dies entspricht mehr der Realität und lohnt sich vor allem bei einer Lokalisation, welche auch das innere des Gehirns berücksichtigt, da die weiße Substanz mit ihrer anisotropen Leitfähigkeit präziser modelliert wird.

Nach der Berechnung des Kopfmodells liegt der Volumenleiter (volume conductor) vor, der in Abbildung \ref{img:bem} dargestellt ist. Dabei wird nur beschrieben wie sich elektrische Aktivität im Gehirn verteilen kann, der Volumenleiter trifft keine Aussage über mögliche Ursprünge elektrischer oder magnetischer Aktivität.

\subsubsection{Koregistrierung}

Die Daten der Physiologie aus der MRT-Messung und die Daten der Aktivität aus der MEG-Messung werden in unterschiedlichen Koordinatensystemen erhoben, da beide Verfahren mit unterschiedlichen Geräten und unterschiedlichen Standards arbeiten (auch herstellerspezifisch). Bei der \emph{Koregistrierung} wird eine Koordinatentransformation durchgeführt, so dass beide Datensätze möglichst gut zueinander passen. Die Transformation kann nicht fehlerfrei durchgeführt werden, die Abweichungen nach der Transformation liegen im Bereich von wenigen Millimetern ???.

Die Koordinatensysteme bei MEG- und EEG-Messungen orientieren sich meist an äußeren anatomischen Merkmalen, wie dem Nasion oder den preauricularen Punkten. Bei bildgebenden Verfahren werden üblicherweise innere anatomische Merkmale, wie die anteriore und posteriore Kommissur. Um eine Vergleichbarkeit zwischen unterschiedlichen Gehirnen zu gewährleisten wird zusätzlich häufig eine Standardisierung der Gehirn-Größe vorgenommen. Dafür wird das Talairach-Tournoux Gehirn oder Vorlagen vom Montreal Neurological Institute (MNI) verwendet.

\subsubsection{Quellraum und Vorwärtsmodell}

Das \emph{Vorwärtsmodell} (\emph{forward solution}) berechnet aus angenommenen Quellen innerhalb des Gehirns die Auswirkung auf die Sensoren außerhalb des Gehirns. Innerhalb des Gehirns werden Dipole modelliert. Das sich ergebende Modell des Gehirns mit den Dipolen wird als \emph{Quellraum} (source space) bezeichnet. Für jeden der gesetzten Dipole wird unter Berücksichtigung der Leitfähigkeit und des Randes (BEM-Netz) die Wirkung auf die Sensoren außerhalb des Gehirns bestimmt. Somit kann für viele Positionen im Gehirn die Wirkung außerhalb des Gehirns abgeschätzt werden.

Die Daten des Vorwärtsmodells werden in einer \emph{Leadfield-Matrix} dargestellt. Sie enthält die Abbildung der Dipole auf die Sensoren. Zur Bestimmung könne wir von folgender Gleichung ausgehen \parencite{maurits2011neurology}:

\begin{equation}
y_i = \int_V \mx{L}_i (\mx{r}) \cdot \mx{j} (\mx{r})\, dV
\label{eq:leadfield}
\end{equation}

Das Potential~$y_i$ am Sensor~$i$ ergibt sich durch Integration des Leadfield-Operators~$\mx{L}_i(\mx{r})$ multipliziert mit der elektrischen Stromdichteverteilung~$\mx{j}(\mx{r})$, jeweils an der Stelle~$\mx{r}$. $\mx{j}(\mx{r})$~ergibt sich aus der Aktivität einer Nervenzelle bzw. der Nervenzellen in unmittelbarer Nähe des betrachteten Punktes und bildet die Ursache für die entstehenden elektrischen und magnetischen Felder.

Die Quelle kann durch diskrete Dipole modelliert werden. Mit Hilfe diese Modellierung kann die Stromdichteverteilung mit Delta-Distributonen beschrieben werden:

\begin{equation}
\mx{j} (\mx{r}) = \mx{S}(\mx{r})\,\delta(\mx{r}-\mx{r}_S)
\end{equation}

Einsetzen in Gleichung~\ref{eq:leadfield} ergibt:

\begin{equation}
y_i = \int_V \mx{L}_i (\mx{r}) \cdot \mx{S}(\mx{r})\,\delta(\mx{r}-\mx{r}_S)\, dV = \mx{S}(\mx{r}_S) \cdot \mx{L}_i(\mx{r}_S)
\label{eq:leadfield2}
\end{equation}

Dabei bezeichnet~$\mx{S}(\mx{r}_S)$ die Stärke des Dipols am Ort der Quelle $\mx{r}_S$. Jeder Datenpunkt kann also mit einem entsprechenden Leadfield-Eintrag und der zugehörigen Quellstärke beschrieben werden.

% Eigentlich ist S und L ein Vektor?
% Die Gleichung ist nur für einen Zeitpunkt und einen Kanal i, sie varriert nur in den Orten
% Oder einfach y zum Vektor machen? Und die Kanäle direkt mit rein nehmen?
% Oder vielleicht doch eher die Zeitpunkt noch mit dazu?

% ############################
% ##### RÜCKWÄRTSMODELL  #####
% ############################

\subsection{Rückwärtsmodell}

Das \emph{Rückwärtsmodell} (\emph{inverse solution}) schätzt auf Basis der Leadfield-Matrix die Aktivitätsquellen im Gehirn. Die Berechnung des Rückwärtsmodells setzt entsprechend das Vorwärtsmodell voraus. Nur wenn bekannt ist wie sich bestimmte Quellen im Gehirn auf die Sensoren außerhalb des Gehirns auswirken, kann berechnet werden wie umgekehrt bestimmte Aktivitätsmuster an den Sensoren mit Quellen im Gehirn zusammenhängen. Für das Rückwärtsmodell können verschiedene Verfahren verwendet werden. Besondere Aufmerksamkeit wird den Methoden \emph{Minimum Norm Estimate} und \emph{Beamforming} gewidmet. Gleichung \ref{eq:leadfield2} bildet den Ausgangspunkt für das Datenmodell der inversen Lösung.

\subsubsection{Methoden zur Bestimmung des Rückwärtsmodell}

Es existieren prinzipiell drei Verfahren zur Bestimmung des Rückwärtsmodells:

\begin{compactitem}
\item Einfache und multiple Dipolmodelle (single and multiple dipole models)
\item Verteilte Dipolmodelle (distributed dipole models)
\item Räumliche Filterung (spatial filtering)
\end{compactitem}

\subsubsection{Einfache und multiple Dipolmodelle}

In den \emph{einfachen und multiplen Dipolmodellen} (single and multiple dipole models) werden nur wenige Quellen angenommen, die einen großen Teil der Varianz in den Daten erklärt \parencite{scherg1990fundamentals}. Es wird zunächst ein Dipol innerhalb des Volumenleiters betrachtet und so lange variiert, bis er einen großen Teil der Varianz der Aktivität an der Kopfoberfläche bzw. an den Sensoren erklärt. Dieses Verfahren wird für einige wenige Dipole wiederholt. Je mehr Dipole verwendet werden, desto höher wird die erklärbare Varianz und desto mehr Lokalisationen können vorgenommen werden. Gleichzeitig ist die zusätzlich erklärte Varianz für jeden neuen einzelnen Dipol immer geringer, weshalb es sich nur lohnt eine überschaubare Anzahl an Dipolen zu betrachten und im Umkehrschluss nur von einer geringen Anzahl an Dipolen auszugehen. In dieser Methode wird zusätzlich zu Gleichung \ref{eq:leadfield2} ein Fehler~$R$ berücksichtigt. Des Weiteren wird der gesamte Zeitverlauf berücksichtigt.

\begin{equation}
\label{eq:leadfield-error}
\mx{y}_i(t) = \mx{S}(\mx{r},t) \cdot \mx{L}_i(\mx{r}) + \mx{R}(t)
\end{equation}

In Summenschreibweise ergibt sich:

\begin{equation}
\label{eq:leadfield-error-sum}
\mx{y}_i = \left( \sum_{j=1}^n \mx{S}_j \cdot \mx{L}_{ij} \right) + \mx{R}
\end{equation}

Es wird versucht den Fehler $\mx{R}$ zwischen Daten $\mx{y}_i$ und Modell $\sum_{j=1}^n \mx{S}_j \cdot \mx{L}_{ij}$ so gering wie möglich zu halten. Dafür wird das Ergebnis des Modells von den Daten abgezogen, der Fehler bzw. das Rauschen bleibt übrig. Dabei wird versucht $n$ klein zu halten.

\begin{equation}
\mx{R} = \mx{y}_i - \left( \sum_{j=1}^n \mx{S}_j \cdot \mx{L}_{ij} \right)
\end{equation}

\subsubsection{Verteilte Dipolmodelle}

In verteilten Dipolmodellen (distributed dipole models) wird davon ausgegangen, dass die Aktivität überall auftritt. Es wird nach der Verteilung der Aktivität im gesamten Gehirn gesucht. Erste Vorschläge zum \emph{Minimum Norm Estimate} (MNE) wurden von \textcite{hamalainen1984interpreting}, \textcite{ilmoniemi1985forward}, \textcite{sarvas1987basic}, sowie \textcite{hamalainen1994interpreting} ausgearbeitet. Einen Überblick gibt \textcite{hamalainen1993magnetoencephalography}.

Wird Gleichung \ref{eq:leadfield-error} umgestellt nach der Quellaktivitätsmatrix~$\mx{S}$ ergibt sich folgende Form:

\begin{equation}
\mx{S} = \mx{L}_i^{-1} ( \mx{y}_i - \mx{R} )
\end{equation}

Es werden sehr viele Quellen betrachtet, deutlich mehr als Sensoren verfügbar sind. Damit ergeben sich unendlich viele exakte Lösungen. Um physikalisch sinnvolle Lösungen zu finden müssen Nebenbedingungen aufgestellt werden. Übliche Nebenbedingungen sind:

\begin{compactitem}
\item Maximale Glättung, LORETA (maximal smoothness)
\item Minimale Energie, L2 (minimum power)
\item Minimale Amplitude, L1 (minimum amplitude)
\end{compactitem}

Dabei entspricht $L2$ der $L2$- bzw. der euklidischen Norm:

\begin{equation}
\|\mx{S}\|_2 = \sqrt{\sum_{k=1}^n |\mx{S}_k|^2}
\end{equation}

Wobei $\mx{S}_k$ dem Dipol am Ort $k$ entspricht. Es wird anschließend diejenige Lösung genommen, für die die euklidische Norm bzw. anschaulich die Gesamtenergie des Gehirns minimal wird.

$L1$ entspricht der $L1$- bzw. Betragssummen-Norm:

\begin{equation}
\|\mx{S}\|_1 = \sum_{k=1}^n |\mx{S}_k|
\end{equation}

Es wird anschließend diejenige Lösung genommen, für die die Betragssummen-Norm bzw. anschaulich die Gesamtamplitude des Gehirns minimal wird.

\subsubsection{Räumliche Filterung}
\label{sec:beam}

Bei der \emph{räumlichen Filterung} (spatial filtering) werden die Zeitverläufe der Aktivitäten der einzelnen Dipole als unkorreliert betrachtet, es wird davon ausgegangen, dass die Dipole sich nicht gegenseitig beeinflussen. Gesucht wird dann nach der Aktivitätswahrscheinlichkeit an jedem Punkt. Dafür wird das gesamte Gehirn mit Hilfe eines einzigen Dipols abgescannt. Kernidee ist ein Verfahren aus der allgemeinen Signaltechnik (z.B. bei Radar- oder Sonarsignalen) auch bei der Lokalisation von Gehirnsignalen einzusetzen. Unterschiedliche Verfahren stehen zur Verfügung:

\begin{compactitem}
\item Beamforming, z.B. LCMV, DICS, SAM
\item Multiple Signal Classification, MUSIC
\end{compactitem}

Die Beamforming-Verfahren werden in Reviews von \textcite{hillebrand2005beamformer}, sowie \textcite{hillebrand2005new} betrachtet. Bei der LCMV Methode \parencite{van1997localization} wird der gesamte Zeitbereich (time domain) erfasst. Ähnlich wie bei der Minimum Norm Lösung wird für jeden Zeitpunkt eine Lokalisierung über das gesamte Frequenzspektrum durchgeführt. Bei der DICS (Dynamic Imaging of Coherent Sources) Methode wird nur eine einzige Quelllösung berechnet. Es wird ein bestimmtes Zeit/Frequenz-Intervall (siehe Zeit-Frequenz-Analyse) ausgewählt. Für diesen Bereich lässt sich eine Lokalisierung bestimmen. Der Vorteil dieses Verfahrens liegt darin, dass bestimmte Bänder (z.B. Alpha-Band) genau betrachtet werden können bzgl. Lokalisierung und Aktivität.

Die folgende Betrachtung wird sich auf \emph{LCMV Beamforming} (Linearly Constrained Minimum Variance Beamforming) beschränken, da diese mit Minimum Norm Estimate vergleichbar ist. Entscheidend dabei ist, dass nur ein Quellort zu einem Zeitpunkt betrachtet wird, die anderen Orte werden nicht berücksichtigt. Für den ersten Ort ergibt sich mit der Summenschreibweise aus Gleichung \ref{eq:leadfield-error-sum} entsprechend:

\begin{equation}
\mx{y}_i = \mx{L}_{i1} \cdot \mx{S}_1 + \mx{N}
\end{equation}

Dabei bezeichnet $\mx{N}$ diejenige Aktivität, welche von allen anderen Orten außer von $\mx{S}_1$ erzeugt wird:

\begin{equation}
\mx{N} = \mx{L}_{i2} \cdot \mx{S}_2 + \ldots + \mx{L}_{in} \cdot \mx{S}_n + \mx{R} = \left( \sum_{j=2}^n \mx{L}_{ij} \cdot \mx{S}_j \right) + \mx{R}
\end{equation}

Jeder beliebige Dipol kann nun als Ausgangspunkt zur Beschreibung der Gesamtaktivität verwendet werden:

\begin{equation}
\label{eq:beam}
\mx{y}_i = \mx{L}_{ij} \mx{S}_j + \mx{N}
\end{equation}

Um jede einzelne räumliche Position betrachten bzw. berechnen zu können, wird ein räumlicher Filter benötigt. Mit diesem lässt sich die Quellaktivität mit den Daten bestimmen. Der räumliche Filter erfüllt maßgeblich zwei Funktionen:

\begin{compactitem}
\item Alle Aktivität $\mx{S}_j$ am betrachteten Ort $j$ soll vollständig durchgelassen werden
\item Rauschen und andere Aktivitäten anderer Orte $\mx{N}$ soll vollständig unterdrückt werden
\end{compactitem}

Die Zeitverläufe der Aktivität an der Quelle $\mx{S}_j$ und die der Aktivitäten an allen anderen Quellen~$\mx{N}$ müssen unkorreliert sein. Die Annahmen des Filters werden im Fall von Korrelationen nicht mehr erfüllt und die Quellen können nicht mehr hinreichend getrennt werden \parencite{van1997localization}, es kommt zu Unschärfe.

Anzumerken ist, dass der räumliche Filter nicht absolut ideal gestaltet sein kann, d.h. das Signal am betrachteten Ort wird nicht vollständig erhalten bleiben und das Signal von allen anderen Orten nicht vollständig unterdrückt werden. Das vorhergesagte Signal ist auf Grund dieser realen Bedingung nicht identisch mit dem ursprünglichen Signal. Das vorgesagte Signal ist gegenüber dem ursprünglichen Signal weniger scharf.

Wird der Filter~$\mx{w}^T$ auf die Daten~$\mx{y}_i$ angewendet, so führt dies zur vorhergesagten Quellaktivität~$\mx{\hat S}$:

\begin{equation}
\label{eq:beam-filter}
\mx{w}_i^T(\mx{r}) \cdot \mx{y}_i = \mx{\hat S}(\mx{r})
\end{equation}

Entgegen den vorigen Modellen muss das Rauschen hier nicht explizit berücksichtigt werden, das Signal wird als Ganzes verrechnet. Gleichung \ref{eq:leadfield} kann geschrieben werden als:

\begin{equation}
\mx{y}_i = \mx{S} \cdot \mx{L}_i
\end{equation}

Eingesetzt in Gleichung \ref{eq:beam-filter} ergibt sich:

\begin{equation}
\mx{w}_i^T \cdot \mx{S} \cdot \mx{L}_i = \mx{\hat S}
\end{equation}

Werden die Bedingungen des räumlichen Filters als Ideal angenommen, dann entspricht die wahre Quellaktivität der vorhergesagten Quellaktivität und es gilt die Identität $\mx{S} = \mx{\hat S}$. Damit gilt:

\begin{equation}
\mx{w}_i^T \cdot \mx{L}_i = 1
\end{equation}

Anschaulich bedeutet dies ein maximales Signal am betrachteten Ort. Für alle anderen Orte wird die Gleichung Null. Allgemein gilt:

\begin{equation}
w^T_{ij} \cdot L_{ik} = \delta_{jk}
\end{equation}

Wobei $j,k$ die Indizes entsprechender Orte darstellen.

Die Bestimmung des Filters erfordert eine gute lineare Schätzung des Zeitverlaufs der Aktivität an einem gegebenen Ort. Eine optimale Gewichtung \parencite[z.B.][]{haykin2008adaptive} wird durch folgenden Filter erreicht:

\begin{equation}
\mx{w}_i = \frac{\mx{C}^{-1} \mx{L}_i}{\mx{L}^T_i \mx{C}^{-1} \mx{L}_i}
\end{equation}

$\mx{C}^{-1}$ bezeichnet die Inverse der Kovarianzmatrix der gemessenen Signale $\mx{y}(t)$. Sie wird mit der verlaufenen Zeit $T$ normiert (???).

\begin{equation}
\mx{C} = \frac{\mx{y}(t)\,\mx{y}(t)^T}{T-1}
\end{equation}

\subsection{Hypothese}
\label{sec:hypo}

Wie in der Einleitung bereits erwähnt, sagt die Hypothese eine relativ hohe Stabilität des LCMV Beamformer-Vefahrens gegen Rauschen voraus. Grundlage der Hypothese ist die Eigenschaft des Beamforer-Vefahrens, dass korrelierte Quellen unterdrückt werden, da es das Ziel ist, eine minimale Varianz zu erreichen \parencite{van1997localization}. Gerade aber Artefakte und Rauschen (insbesondere externe Einflüsse wie die des Stromnetzes) haben die Eigenschaften relativ Konstant über alle Kanäle hinweg aufzutreten. Entsprechend müsste hier eine hohe Korrelation der Signale vorliegen, was zu einer systematischen Unterdrückung des Rauschens durch den LCMV Beamformer-Ansatz führen sollte.

Auf der anderen Seite sollte Minimum Norm Estimate Probleme haben mit Rohdaten umgehen zu können. Die in den Rohdaten nicht unterdrückten äußeren Quellen dürften den Versuch der Minimierung der Energie (bzw. der L2-Norm) deutlich verfälschen. Äußere Signale könnten bei der Kalkulation berücksichtigt werden, obwohl sie eigentlich nicht berücksichtigt werden sollen. Zusammengefasst:

\begin{compactitem}
\item Hauptthese: LCMV Beamformer ist robust gegen Rauschen (intrinsische Rauschunterdrückung)
\item Nebenthese: Minimum Norm Estimate ist nicht robust gegen Rauschen
\end{compactitem}

% #####################
% ##### METHODIK  #####
% #####################

\newpage

\section{Methodik}
\label{sec:methodik}

\subsection{Grundlage}

\subsubsection{Verwendeter Datensatz}

Die verwendeten Daten wurden aus einem Experiment von \textcite{herrmann2011syntactic} übernommen. Dabei sollten die neuronalen Prozesse bei der Satzverarbeitung des menschlichen Gehirns untersucht werden. Die Sätze wurden dabei vorgelesen und per Kopfhörer von den Pobanden angehört. Zum einen wurden die Effekte einer syntaktischen Verarbeitung betrachtet. Sätze wurden in einer korrekten grammatikalischen Reihenfolge (Standard) oder einer falschen Reihenfolge (Deviant) präsentiert. Dabei wurde in früheren Experimenten ein ELAN (Early Left Anterior Negativity) Potential beobachtet, sofern die grammatikalische Wortfolge falsch war. Zum anderen wurden die Effekte einer räumlichen Abweichung gesprochener Sätze betrachtet. Die interaurale Laufzeit (Interaureal Time, ITD) wurde entsprechend variiert, so dass der Lautsprecher an einem Ohr relativ zum Lautsprecher am anderen Ohr die Sätze verzögert ausgab. In früheren Experimenten wurde hier eine MMN (Mismatch Negativity) beobachtet (siehe auch Abschnitt \nameref{sec:erf} auf Seite \pageref{sec:erf}).

Die beiden Effekte, die zu ELAN und MMN führen treten in Interaktion, wie \textcite{hahne2002differential} erstmals feststellten. Die Hypothese der Studie von \textcite{herrmann2011syntactic} lautete, dass die Verarbeitung dieser beiden Effekte, sofern sie gleichzeitig auftreten, im Gehirn zwar in unterschiedlichen Regionen, aber parallel verarbeitet werden.

Wie genau sieht eine Abweichung aus? Was sind Deviants???

Welche Blöcke wurden verwendet??? 1,3,4,6: Warum???

Aus den Daten waren für den Fall der vorliegenden methodischen Untersuchung vor allem die MMN von Interesse. Das Potential ist im Zeitverlauf recht deutlich zu erkennen und kann für eine Lokalisation gut verwendet werden. Zwar wird ein schlechteres Signal-Rausch-Verhältnis erwartete (siehe Abschnitt \nameref{sec:snr} auf Seite \pageref{sec:snr}), als es z.B. im Oddball Paradigma \parencite{naatanen2004mismatch} vorkommt, die verwendeten Daten basieren jedoch auf einem Experiment, welches einer realistischen bzw. alltäglichen Verarbeitung im Gehirn entspricht (Verarbeitung von gehörten Sätzen). Da es sich in dem Experiment, auf dem die verwendeten Daten basieren, um ein Experiment zur Sprachverarbeitung handelt, ist ein MMN-Potential im auditorischen Kortex zu erwarten (siehe auch Abschnitt \nameref{sec:audicort} auf Seite \pageref{sec:audicort}).

\subsubsection{Verwendete Geräte}

MEG/MRT

Im verwendeten MEG, dem \emph{Vectorview by Elekta-Neuromag Oy, Helsinki} werden insgesamt 306 Sensoren für die Messung der Gehirnsignale verwendet. Davon sind 204 Gradiometer und 102 Magnetometer. Die Sensoren bestehen aus DC SQUIDs ... Helium ...

Neben den Sensoren zur Messung der Gehirnsignale werden weitere Sensoren zu Messung der Augenbewegung (EOG ???) und ??? verwendet.

\subsubsection{Software zur Analyse}
\label{sec:software}

Zur Verarbeitung der vorliegenden Daten wurde verschiedene Software verwendet. Gearbeitet wurde auf einem \emph{GNU/Linux}-System mit \emph{Ubuntu} in Version 12.04.5 LTS. Die Auswertung der bildgebenden Daten des MRT erfolgte mit \emph{Freesurfer} in Version 5.3.0. Die Signal Space Separation (SSS) und Movement Correction (MC) wurde mit \emph{MNE} in Version 2.7.5-3435 durchgeführt (siehe auch Abschnitt \nameref{sec:maxfilter} auf Seite \pageref{sec:maxfilter}). MNE basiert auf dem \emph{Neuromag} Softwarepaket in Version 6. Alle weiteren Analysen erfolgten mit der Open Source Paket \emph{FieldTrip} in Version 20150225, welches in \emph{Matlab R2015a} verwendet wurde.

% Ist das so korrekt ???

\subsection{Verfahren}

Um die Hypothese zu überprüfen wurden die Daten aus dem oben genannten Datensatz verwendet. Die Quellrekonstruktion der MMN-Aktivität sollte mit LCMV Beamformer und Minimum Norm Estimate durchgeführt werden. Dazu wurden die Daten von zwei Versuchspersonen verwendet. Eine Versuchsperson (im Folgenden als \texttt{pa07} bezeichnet), wies ein sehr ruhiges Verhalten auf. Es kam nur zu wenigen Kopfbewegungen während des Versuchs. Die andere ausgewählte Versuchsperson \texttt{pa10} bewegte ihren Kopf sehr viel. Deren Daten dürften daher zu einer fehlerhafteren Rekonstruktion führen. Die entsprechende Bewegungsanalyse wird im Abschnittes \nameref{sec:bewegung} auf Seite \pageref{sec:bewegung} beschrieben.

Von beiden Versuchspersonen lagen 4 Blöcke in entsprechenden Versuchsbedingungen vor. Die Daten der 4 Blöcke wurden zusammen genommen und gemeinsam verrechnet. Dabei mussten die spezifischen Eigenschaften der Quellrekonstruktionsverfahren beachtet werden. Entsprechende Betrachtungen wurden in den folgenden Abschnitten \nameref{sec:lead-beam-mne} und \nameref{sec:amplitud} vorgenommen.

Die Rekonstruktion wurde in folgenden Bedingungen für beide Versuchspersonen durchgeführt:

\begin{compactitem}
\item LCMV Beamformer auf Basis von Rohdaten
\item LCMV Beamformer auf Basis von SSS-korrigierten Daten
\item LCMV Beamformer auf Basis von MC-korrigierten Daten
\item Minimum Norm Estimate auf Basis von Rohdaten
\item Minimum Norm Estimate auf Basis von SSS-korrigierten Daten
\item Minimum Norm Estimate auf Basis von MC-korrigierten Daten
\end{compactitem}

Bei Versuchsperson \texttt{pa10} sollten auf Grund der Bewegungskorrektur deutlich bessere Ergebnisse bei MC-korrigierten Daten zu erwarten sein, im Vergleich zu Roh- und SSS-korrigierten Daten.

\subsection{Vorverarbeitung}

Grafik zum Verfahren!

Zur Verwendung kam ein MEG-Datensatz mit den oben beschriebenen Daten und ein MRT-Datensatz, der einen einfachen Scan des Gehirns der Versuchspersonen enthielt. Für den MRT-Datensatz wurde zunächst eine Separation mittels Freesurfer durchgeführt. Während die physiologischen Informationen des MRT-Datensatzes im ??-Koordinatensystem vorlagen .. Die physiologischen Daten des MRT lagen im ???-Koordinatensystem vor, während die Aktivitätsdaten des MEG im ???-Koordinatensystem vorlagen. Wie sind die Korrdinatensysteme definiert?? Abweichungen in mm angeben.

BEM-Netz: In dieser Analyse wurde ein Auflösung von XXXX gewählt.
Berechnung der Quellen nur am Außenbereich, daher BEM (isotrop, graue Substanz außen) ok.

Anzahl der modellierten Dipole im Source Space (Vorwärtsmodell): 10242 pro Hemisphäre

Preprocessing: Filter, Rejection, Definition (Baseline), etc.

Averaging blockwise

\subsection{Leadfieldmatrix bei Beamformer und Minimum Norm} % "Vorwärtsmodell berechnen" -> Umbenennen?
\label{sec:lead-beam-mne}

Die Liedfield-Matrix wird für eine bestimmte Kopfposition bestimmt. Da Probanden ihren Kopf nie exakt an einem Ort halten, muss genau genommen für jede vorkommende Kopfposition bestimmt werden, wie sich in diesem Fall die Quellen auf die Sensoren auswirken (Vorwärtsmodell). Während bei den SSS- und den MC- Daten kein Problem auftritt, da hier die Kopfposition korrigiert wird, ist dies bei den Rohdaten problematischer. Bei Verwendung der Rohdaten muss also berücksichtigt werden, dass die Leadfield-Matrix nur für die initiale Kopfposition korrekt ist, alle anderen Kopfpositionen enthalten im Rückwärtsmodell entsprechende Fehler.

Vor allem bei der Bewertung des Beamformer-Verfahrens muss dieser Aspekt zwingend beachtet werden, da hier mit den Rohdaten gerechnet wird. Um einen aussagekräftigeren Vergleich zu erhalten, wäre hier eine Bewegungskorrektur nötig, die explizit keine Rauschunterdrückung durchführt. Maxfilter kann in diesem Fall also nicht verwendet werden, da die Bewegungskorrektur mit Rauschunterdrückung einher geht. Eine Implementierung eines solchen Bewegungs-Korrektur-Verfahrens könnte die Beamformer-Lösung verbessern, vor allem bei solchen Probanden, die sich viel bewegen.
Kopfkorrektur bei Rohdaten und rauschunterdrückten Daten

Das SSS-Verfahren von Maxfilter beinhaltet neben der Trennung der Signale in einen inneren und einen äußeren Bereich auch eine Kopfkorrektur, da ein absolutes Stillhalten der Versuchspersonen keinen realen Versuchsbedingungen entspricht. Dabei wird die Position des Kopfes bezüglich den Sensoren standardisiert, die Kopfposition zu Beginn des ersten Blocks wird als Standard definiert. Die Signale die aus dem Gehirn kommen müssen von der gleichen Quelle aus immer auch die gleichen Sensoren ansprechen, andernfalls kommt es in der späteren Berechnung zu Fehlern. Wird eine falsche Kopfposition angenommen, werden gemessene Signale an den Sensoren später einer falschen bzw. verschobenen Quelle zugeordnet.

Während bei MC (movement correction) angenommen wird, dass der Kopf sich innerhalb eines Blocks bewegt, wird bei SSS angenommen, dass der Kopf innerhalb eines Blockes an der gleichen Position bleibt. Zwischen den Blöcken wird jedoch auch bei SSS korrigiert. Alle späteren Blöcke werden am Startpunkt auf die Position des ersten Blocks gesetzt, die Positionen der Sensoren (??) werden entsprechend umgerechnet.

Werden die SSS oder MC-Daten verwendet können im Preprocessing alle Daten, d.h. über alle Trials in allen Blöcken gemittelt werden, da die Kopfposition bereits korrigiert ist und jeder Sensor konstant die Daten desselben Ortes erfasst. Werden jedoch Rohdaten verwendet, dann ist nicht mehr sichergestellt, dass jeder Sensor die Daten des gleichen Ortes erfasst. Eine Mittelung über Rohdaten hätte zur Folge, dass eigentlich vorhandene Aktivitäten verschwinden können oder nicht vorhandene Aktivitäten auftauchen. Eine Mittelung der Trials zwischen den Blöcken kommt also zunächst nicht in Frage.

Theoretisch gibt es zwei Möglichkeiten mit Rohdaten umzugehen:

Eine Möglichkeit ist die Korrektur der Kopfpositionen, ohne jedoch eine Rauschunterdrückung vorzunehmen. So bietet FieldTrip z.B. die Funktion \texttt{ft\_megrealign}. Die Korrektur der Kopfposition erfolgt durch eine Projektion. Es wird zunächst eine grobe Quellrekonstruktion durchgeführt und es werden Standard-Positionen der Sensoren festgelegt, zum Beispiel vom Beginn des ersten Blocks. Die zeit-gemittelten Daten werden dann mit Hilfe der rekonstruierten Quelle projiziert (???). Die dabei entstehenden Signale für die standardisierte Position werden anschließend neu berechnet. Bei diesem Verfahren kommt es wegen der enthaltenen Quellrekonstruktion zu Fehlern in den Daten, die Daten sind lediglich interpoliert und enthalten nach der Korrektur nicht mehr die vollständigen Informationen. Es handelt sich nicht mehr um reine Rohdaten, weshalb dieses Verfahren nur einen Kompromiss darstellen würde.

Eine zweite Möglichkeit ist das Mitteln der Quellaktivität. Für jeden Block kann eine eigene Leadfield-Matrix für das Vorwärtsmodell bestimmt werden. Nach anschließender Quelllokalisation können die Aktivitäten an den Quellen gemittelt werden. Der Rechenaufwand ist zwar etwas erhöht, da für jeden Block die Leadfield-Matrix bestimmt werden muss, gleichzeitig bietet dieses Verfahren jedoch den Vorteil, dass es auch auf die rauschunterdrückten Daten von Maxfilter (SSS, MC) angewendet werden kann. Auch hier kann im Preprocessing absichtlich auf eine Mittelung zwischen den Blöcken verzichtet werden. Die Leadfield-Matrizen können dann auch hier blockweise bestimmt und die Quellaktivitäten am Ende gemittelt werden. Diese Möglichkeit bietet damit eine optimale Vergleichbarkeit zwischen der Verwendung von Rodaten und rauschunterdrückten Daten, unabhängig vom verwendeten Lokalisationsverfahren.

\subsection{Rückwärtsmodell}

\subsection{Vergleichbarkeit der Amplituden}
\label{sec:amplitud}

% #######################
% ##### ERGEBNISSE  #####
% #######################

\newpage
\section{Ergebnisse}
\label{sec:ergebnisse}

Was kam raus?

\subsection{Bewegungsprofile}
\label{sec:bewegung}

Bewegungen

\subsection{Signal-Rausch-Verhältnis}
\label{sec:snr}

Das Signal-Rausch-Verhältnis (signal-noise-ration, SNR) gibt das Amplitudenverhältnis der Daten an. Die Daten werden dabei in einen Rausch-Anteil $P_R$ und einen Signal-Anteil $P_S$ zerlegt. Allgemein gilt:

\begin{equation}
SNR = \frac{P_S}{P_R}
\end{equation}

Als Rausch-Anteil wurden die ersten 100 ms gewählt. Dies entspricht der Baseline. Als Signal-Anteil wurde die MMN verwendet, welche im Bereich 150 ms bis 250 ms liegt. Damit ergeben sich zwei Zeitbereiche von je 100 ms, die in den Butterfly-Diagrammen der Rohdaten (siehe Abbildungen ???) dargestellt sind. Verwendet wurden 225 der 13?? Trials pro Block, diese entsprechen der Deviant-Bedingungen, da nur hier ein Signal für die MMN erwartet wird.

Es wurden nur jene Kanäle für die Berechnung verwendet, welche am Ort der Entstehung der MMN entsprechende Signale messen. Dafür wurde zunächst das Amplitudenmaximum aus allen Trials und Zeitpunkten bestimmt. Für die zwei berechneten Versuchspersonen ergaben sich das Maximum an Kanal \texttt{MEG014} für \texttt{pa10} und Kanal \texttt{MEG151} für \texttt{pa07}. Das leicht verschobene Maximum ist auf eine unterschiedliche Position des Kopfes der Versuchsperson im MEG-Helm während des Versuchs zurück zu führen. Nachdem die Maxima bestimmt wurden, wurden die umliegenden Kanäle in die Berechnung des Signals integriert. Die verwendeten Kanäle sind:

\texttt{MEG013}, \texttt{MEG014}, \texttt{MEG021}, \texttt{MEG024}, \texttt{MEG151}, \texttt{MEG154}, \texttt{MEG152}, \texttt{MEG161}

In der Karte (Abbildung ???) wird deutlich, dass die Kanäle wie zu erwarten für die MMN im linken temporalen Bereich liegen (Stimulation erfolgte linksseitig). Von den Kanälen wurden sowohl die Magnetometer, als auch die beiden Gradiometer berücksichtigt.

Zur Berechnung des SNR wurden die Rohdaten verwendet, was eine erneute Vorverarbeitung nötig macht. Dabei wurde der gesamte Datensatz nach obigen Kriterien in die Trials zerteilt. Jeder Trail wurde anschließend in einen Rausch- und einen Signal-Anteil getrennt. Von der Baseline (Rausch-Anteil) wurde der Mittelwert gebildet.

\begin{equation}
\bar{b}_{ik} = \frac{1}{n_b} \sum_{j=1}^{n_b} b_{ijk}
\end{equation}

Dabei ist $i$ der Index der Kanäle, $j$ der Index der Zeitpunkte und $k$ der Index der Trials. $n_b$ entspricht der Anzahl der Zeitpunkt, die innerhalb der Baseline berücksichtigt werden mit $n_b = 100$. $b_{ijk}$ entspricht einer dreidimensionalen Matrix, welche die Amplituden für alle Trials, Zeitpunkt und Kanäle enthält. Gemittelt über die Zeitpunkt ergibt sich eine zweidimensionale Matrix $b_{ik}$, welche eine mittlere Amplitude für jeden Trial und jeden Kanal enthält.

Dieser Mittelwert wird für jeden einzelnen Zeitpunkt innerhalb der gesamten Aktivität (sowohl für den Rausch-Anteil, als auch für den Signal-Anteil) subtrahiert, um das mittlere Rauschen aus der Aktivität heraus zu rechnen.

\begin{equation}
\hat{b}_{im} = b_{im} - \bar{b}_{ik}
\hat{s}_{im} = s_{im} - \bar{b}_{ik}
\end{equation}

Dabei wurden die Zeitpunkt $j$ und die Trials $k$ zusammengefasst im Index $m$, eine Trennung dieser beiden Indizes ist an der Stelle nicht mehr notwendig, es handelt sich nur noch um eine Anzahl von Trials $m$. $\hat{b}_{im}$ entspricht dem korrigierten Rausch-Anteil und $\hat{s}_{im}$ dem korrigierte Signal-Anteil.

Die neuen Matrizen werden anschließend durch die Anzahl der Zeitpunkt geteilt. Dieser formale Schritt ist nötig für den Fall, dass sich die Zeitbereiche der beiden Anteile unterscheiden. In diesem Fall liegen beide bei $n_b = n_s = 100$ Zeitpunkten, so dass dieser Schritt auch ausgelassen werden könnte. Der Vollständigkeit halber:

\begin{equation}
\tilde{b}_{im} = \frac{\hat{b}_{im}}{n_b} \quad \text{und} \quad \tilde{s}_{im} = \frac{\hat{s}_{im}}{n_s}
\end{equation}

Im folgenden Schritt werden die Kovarianzenfür die beiden Anteile bestimmt.

\begin{equation}
b_{ij} = \tilde{b}_{im} \cdot \tilde{b}_{mj} \quad \text{und} \quad s_{ij} = \tilde{s}_{im} \cdot \tilde{s}_{mj}
\end{equation}

$b_{mj}$ bzw. $s_{mj}$ entspricht dabei der transponierten Matrix von $b_{im}$ bzw. $s_{im}$, wobei $i$ und $j$ jeweils den Index des Kanals bezeichnet. Die Varianzmatrizen $b_{ij}$ und $s_{ij}$ ist quadratisch und enthält die Varianzen der Amplituden zwischen allen Kanälen. Die Diagonalelemente der Matrizen entsprechen dann den Kovarianzen der Kanäle. Die Kovarianzen werden komponentenweise dividiert und anschließend gemittelt:

\begin{equation}
SNR = \sum_i \delta_{ij} \frac{s_{ij}}{b_{ij}}
\end{equation}

Für die verwendeten Daten eines auditorischen Experiments, welches auf einer komplexen Satzverarbeitung basiert ist kein sehr hohes SNR zu erwarten, es sollte jedoch oberhalb von $3$ liegen. Dieser Wert wird von der Software \emph{MNE} als Grenzwert vorgeschlagen ???.

\begin{table}[t]
\caption{}
\label{tab:snr}
\vspace*{3mm}
\begin{tabularx}{\textwidth}{cll}
Block & pa07 & pa10 \\
\hline
1 & $3.123$ & $3.915$\\
3 & $2.942$ & $3.144$\\
4 & $2.589$ & $3.875$\\
6 & $2.715$ & $3.348$\\
\hline
\end{tabularx}
\vspace*{3mm}
\caption*{Signal-Rausch-Verhältnis für zwei Versuchspersonen in jeweils 4 Blöcken. Das Verhältnis sollte im Idealfall einen Wert von $3$ überschreiten.}
\end{table}

Die Ergebnisse sind in Tabelle \ref{tab:snr} dargestellt. Deutlich wird, dass das Signal-Rausch-Verhältnis um den Wert von $3$ liegt. Während \texttt{pa07} eher leicht unterhalb von $3$ liegt, sind die Werte von \texttt{pa10} gut oberhalb von $3$. Das Signal-Rausch-Verhältnis spricht dafür, dass die Daten zur Lokalisation geeignet sein sollten, die Ergebnisse jedoch etwas verrauscht werden könnten.

\subsection{Quellrekonstruktionen und Zeitverläufe}

Bilder

\subsection{Anpassungsgüte}

Nur für MNE?

% #######################
% ##### DISKUSSION  #####
% #######################

\newpage

\section{Diskussion}
\label{sec:diskussion}

Präsentation: Therefore, uncorrelated noise (e.g., random system noise) will be amplified by the weights in a non-uniform manner, with increasing distortion with increasing distance from the sensors 

MEG-Buch S. 164: Since the adaptive spatial fi lters computed using Equation (7–3) are dependent on the leadfi eld matrix G , beamforming—like the MNE/MCE methods for distributed source modeling—does not provide accurate estimates of deep sources. This is essentially due to the fact that the fi eld patterns at the scalp of neighboring dipole sources approaching the center of the head are generally more similar to each other (i.e., more spatially correlated) than164
MEG: An Introduction to Methods the fi elds of neighboring dipoles close to the surface. Particularly in the presence of noise, this leads to larger localization errors. Primarily because of this “spatial leakage,” beamformers tend to overestimate the signal power of deeplying sources, which makes it diffi cult to interpret the “raw” beamformer signal amplitude estimates.

Ist Unterschied Roh/SSS zu MC größer bei pa10?

\newpage
\section{Literaturverzeichnis}

\printbibliography[heading=none]

%\includepdf[pages=-]{appendix/anhang-trennblatt-versuchsaufbau.pdf}

\end{document}